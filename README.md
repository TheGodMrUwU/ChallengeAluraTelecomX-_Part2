# Telecom X Â· Parte 2 â€” Churn Modeling (Colab)

**Objetivo.** Tomar el dataset tratado de la Parte 1, **mapear** columnas al esquema analÃ­tico, **crear el target** `Cliente_cancelado`, entrenar y comparar modelos (LogReg / LogReg+SMOTE / RandomForest), **evaluar** con mÃ©tricas robustas y **generar entregables** (CSV Ãºnico + mÃ©tricas + tablas + figuras).

---

## ğŸ“¦ Datos de entrada

Archivo de la Parte 1: `telco_entregable_unico.csv` (o la ruta que uses).

**Columnas que reconoce el flujo** (se mapean automÃ¡ticamente si existen):

| En tu CSV (Parte 1)                                               | Usado como (Parte 2)                                 |
| ----------------------------------------------------------------- | ---------------------------------------------------- |
| `Activo`                                                          | (si falta target) â†’ `Cliente_cancelado = 1 - Activo` |
| `Ciudadano_65+`                                                   | `Mayor_de_65_aÃ±os`                                   |
| `Dependientes`                                                    | `Tiene_Dependientes`                                 |
| `Meses_Contrato`                                                  | `Meses_Contratados`                                  |
| `Contrato`                                                        | `Tipo_de_Contrato`                                   |
| `MÃ©todo_Pago`                                                     | `Metodo_Pago`                                        |
| `Cargos_Mensuales`                                                | `Cobro_Mensual`                                      |
| `Cargo_Total`                                                     | `Gasto_Total`                                        |
| *(opcionales)* `Servicio_Internet`, `GÃ©nero`, `Servicio_TelÃ©fono` | Se usan si estÃ¡n                                     |

> El pipeline tambiÃ©n normaliza `SÃ­/No` â†’ `1/0` (tolerante a acentos/espacios) y tipa numÃ©ricos.

---

## ğŸ§± Estructura (Colab por celdas)

1. **InstalaciÃ³n** (solo si falta): `imbalanced-learn` para SMOTE.
2. **Imports & Carga**: lee `telco_entregable_unico.csv`, crea `outputs/`.
3. **Mapeo & SelecciÃ³n**: renombra columnas, crea `Cliente_cancelado` si falta, castea tipos y elige columnas base (+ extras si hay).
4. **Encoding & Split**: mapea `SÃ­/No`, define `X/y`, **train/test** estratificado (80/20).
5. **Preprocesamiento & Modelos**: `ColumnTransformer` con imputer+scaler+OHE y tres pipelines:

   * `logreg_weighted`: RegresiÃ³n LogÃ­stica con `class_weight='balanced'`.
   * `logreg_smote`: LogReg + **SMOTE** (oversampling sintÃ©tico) dentro del pipeline.
   * `rf_weighted`: RandomForest con `class_weight='balanced_subsample'`.
6. **Entrenamiento & MÃ©tricas**: `accuracy`, `precision`, `recall`, `f1`, **ROC AUC**, **PR AUC**. SelecciÃ³n del **mejor por ROC AUC** (empate â†’ F1).
7. **Curvas & Matriz**: ROC, Precisionâ€“Recall y Matriz de ConfusiÃ³n del mejor.
8. **Exportables**:

   * `outputs/telco_parte2_unico.csv` (dataset analÃ­tico mapeado).
   * `outputs/metrics_parte2.json` (mÃ©tricas del mejor).
9. **(Opcional) Importancias**: Top variables (RF) o coeficientes (LogReg).
10. **Celda final (reporting)**: guarda **tablas** y **figuras** clave en:

    * `outputs/tables/` (CSV): report de clasificaciÃ³n, comparativa de modelos, tasas por segmento, resumen numÃ©rico, matriz de correlaciÃ³n, scores de probas.
    * `outputs/figs/` (PNG): matriz de confusiÃ³n, ROC, PR, tasas por segmento, correlaciÃ³n, importancias/coeficientes.

---

## â–¶ï¸ CÃ³mo ejecutar

1. Abre el notebook en **Google Colab**.
2. Sube `telco_entregable_unico.csv` o monta Drive y ajusta la ruta en la **Celda 2**.
3. Corre **todas las celdas en orden**.
4. Revisa los entregables en `outputs/`.

---

## ğŸ“Š MÃ©tricas y criterios

* **Primarias:** ROC AUC (ranking de riesgo), PR AUC (robusta a desbalance), **F1** y **Recall** de la clase 1 (cancelÃ³).
* **SelecciÃ³n del mejor:** mayor **ROC AUC** (si empata, mejor **F1**).
* **Curvas:** ROC y Precisionâ€“Recall para inspecciÃ³n visual.
* **Matriz de ConfusiÃ³n:** errores por clase (Ãºtil para coste de falsos negativos).

---

## ğŸ› ï¸ PersonalizaciÃ³n rÃ¡pida

* **Umbral de decisiÃ³n** (subir recall â†“ precisiÃ³n):

  ```python
  y_prob = best_pipe.predict_proba(X_test)[:,1]
  umbral = 0.35  # ejemplo
  y_pred = (y_prob >= umbral).astype(int)
  ```
* **SMOTE**:

  * Cambia el balance interno: `SMOTE(random_state=42, sampling_strategy=0.7)`
* **RandomForest**:

  * HiperparÃ¡metros clave: `n_estimators`, `max_depth`, `min_samples_leaf`.

---

## ğŸ§© Salidas esperadas

* `outputs/telco_parte2_unico.csv` â€” dataset final (target + features mapeadas).
* `outputs/metrics_parte2.json` â€” resumen del mejor modelo.
* `outputs/tables/` â€” informes en CSV (clasif., comparativas, tasas, correlaciÃ³n, resumen por clase, probas).
* `outputs/figs/` â€” PNG (confusiÃ³n, ROC/PR, tasas por segmento, correlaciÃ³n, importancias).

---

## ğŸ§¯ Troubleshooting

* **`Input y contains NaN`**: el target tenÃ­a vacÃ­os. La celda de normalizaciÃ³n crea `Cliente_cancelado` desde `Activo` y **filtra filas sin target**. Recorre la Celda 3â€“4.
* **`KeyError` en columnas**: tu CSV no trae algÃºn nombre esperado. Revisa la **tabla de mapeo** de arriba o ajusta el dict `alias`.
* **`imbalanced-learn` no encontrado**: corre la **Celda 1** (instalaciÃ³n).
* **One-Hot con categorÃ­as nuevas**: `handle_unknown='ignore'` ya lo cubre; asegÃºrate de no re-entrenar el OHE con test.

---

## ğŸ“ Reproducibilidad

* `random_state=42` en splits/modelos.
* Preprocesamiento, SMOTE y modelo viven **en el mismo pipeline** (evita fugas de datos).
* Split **estratificado** para mantener proporciones.

---

## ğŸ“œ Licencia

Uso educativo/demostrativo. Ajusta a la polÃ­tica de tu organizaciÃ³n si lo despliegas en producciÃ³n.
